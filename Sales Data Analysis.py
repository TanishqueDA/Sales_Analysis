# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dHUJLqnRXtxy_k6Ixe-ho9YutSHopdZm
"""

#Data Collection
import numpy as np
import pandas as pd
import datetime as dt

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

Sales_data = pd.read_csv('Sales_Data.csv')
print(Sales_data)

from google.colab import drive
drive.mount('/content/drive')

#Data Cleaning
Sales_data.head()

Sales_data.tail()

Sales_data.dtypes

Sales_data.info()

Sales_data.shape

Sales_data.sort_values("Product")

Sales_data.isna().sum()

Sales_data[Sales_data.isna()]

Sales_data.dropna(inplace=True)

size = Sales_data.size
shape = Sales_data.shape
df_ndim = Sales_data.ndim

print(size)
print(shape)
print(df_ndim)

Sales_data.columns = Sales_data.columns.str.strip()
print(Sales_data.columns)

Sales_data.describe()

#Exploratory Data Analysis (EDA)
#What was the best month for sale and how much was earned that month?
temp=Sales_data.groupby(['Month']).sum()[['Sales']]
temp

plt.style.use('default')
plt.figure(figsize=(8,4))

plt.bar(temp.index,temp['Sales'])
plt.title('Monthly Sales',size=14)
plt.xticks(temp.index)
plt.xlabel('Month Number',size=12)
plt.ylabel('Sales (USD)',size=12)
plt.show()

#Which city has the highest sales?
city_sales=Sales_data.groupby(['City']).sum()['Sales'].sort_values(ascending=True)
city_sales

plt.figure(figsize=(8,4))

plt.barh(city_sales.index,city_sales.values,color='green')
plt.title('City Sales',size=14)

plt.xlabel('Sales (USD)',size=12)
plt.ylabel('City',size=12)
plt.show()

"""# What time should the advertisement be displayed to maximize the likelihood of customer's buying product?"""

# What time should the advertisement be displayed to maximize the likelihood of customer's buying product?
# Check the values in the 'Order Date' column
Sales_data['Order Date'].head()

# Find the row with the invalid date
invalid_date_row = Sales_data[Sales_data['Order Date'] == "11-"].index

# Print the row with the invalid date
print(Sales_data.loc[invalid_date_row])

Sales_data['Order Date']=pd.to_datetime(Sales_data['Order Date'])

Sales_data.head()

Sales_data['Hour']=Sales_data['Order Date'].dt.hour

Sales_data.head()

# Convert 'Order Date' column to datetime
Sales_data['Order Date'] = pd.to_datetime(Sales_data['Order Date'])

# Ensure 'Sales' column is of numeric type
Sales_data['Sales'] = pd.to_numeric(Sales_data['Sales'])

# Check the DataFrame after converting 'Order Date'
print("\nDataFrame after converting 'Order Date' to datetime:")
print(Sales_data)

# Extract hour from 'Order Date' and create a new 'Hour' column
Sales_data['Hour'] = Sales_data['Order Date'].dt.hour

# Display the DataFrame with the new 'Hour' column
print("\nDataFrame with 'Hour' column:")
print(Sales_data)

# Display the data types to ensure correctness
print("\nData types of the DataFrame:")
print(Sales_data.dtypes)

# Group by the 'Hour' column and sum the 'Sales' column
temp1 = Sales_data.groupby(by=['Hour'])[['Sales']].sum()

# Display the result
print("\nSum of Sales grouped by Hour:")
print(temp1)

plt.figure(figsize=(10,3))

plt.plot(temp1.index,temp1.values,color='red',marker='o')
plt.title('Hourly Sales',size=14)
plt.xticks(temp1.index)
plt.xlabel('Hours',size=12)
plt.ylabel('Number of Orders',size=12)
plt.show()

"""From the line chart above people likely to purchase product during 10 AM-2 PM and 5 PM-9 PM which is the right time to display the advertisement whereas least active during early morning between 1 AM-6 AM."""

# Top 10 Products Sold
temp1=Sales_data.groupby(by=['Product'])[['Quantity Ordered']].sum().sort_values(by=['Quantity Ordered'],
                                                                    ascending=False).reset_index().head(10)

plt.figure(figsize=(8, 4))

ax = sns.barplot(data=temp1, y='Product', x='Quantity Ordered', palette='viridis')
for i in ax.containers:
    ax.bar_label(i, padding=-37, size=10, color='white', fontweight='bold')

plt.title('Top 10 Products', size=14)
plt.ylabel('Products', size=12)
plt.xlabel('Quantity Ordered', size=12)
plt.xticks([])

plt.show()

#Find the top products and why it is sold mostly
temp2=Sales_data.groupby(by=['Product'])[['Price Each']].mean()[['Price Each']].sort_values(by=['Product']).reset_index()
temp2

temp3=Sales_data.groupby(by=['Product'])[['Quantity Ordered']].sum().sort_values(by=['Product']).reset_index()

fig, ax1 = plt.subplots(figsize=(10,5))
plt.style.use('default')
ax2 = ax1.twinx()

sns.barplot(x='Product', y='Quantity Ordered',data=temp3,ax=ax1, color='g')
sns.lineplot(x='Product', y='Price Each',marker='o',data=temp2, ax=ax2, color='r')

ax1.set_xticks(ticks=np.arange(len(temp3)),labels=temp3['Product'],rotation=90)
ax2.set_ylabel('Average Price')

plt.title('Quantity Ordered vs Average Price')

plt.show()

# Assuming Sales_data is already defined and loaded

# Extract day of the week from Order Date
Sales_data['Order Date'] = pd.to_datetime(Sales_data['Order Date'], format='%d-%m-%Y %H:%M')
Sales_data['Day of Week'] = Sales_data['Order Date'].dt.dayofweek

# Extract state from Purchase Address
Sales_data['State'] = Sales_data['Purchase Address'].apply(lambda x: x.split(', ')[-1].split(' ')[0])

# One-hot encode Product and City
Sales_data = pd.get_dummies(Sales_data, columns=['Product', 'City', 'State'])

# Standard scale Quantity Ordered, Price Each, and Sales
scaler = StandardScaler()
Sales_data[['Quantity Ordered', 'Price Each', 'Sales']] = scaler.fit_transform(Sales_data[['Quantity Ordered', 'Price Each', 'Sales']])

# Create interaction term
Sales_data['Quantity*Price'] = Sales_data['Quantity Ordered'] * Sales_data['Price Each']

# Display the first few rows of the dataframe
Sales_data.head()

# Assuming Sales_data is already defined and processed as in your previous steps

# Split the data into features and target
X = Sales_data.drop(columns=['Unnamed: 0', 'Order ID', 'Order Date', 'Purchase Address', 'Sales'])
y = Sales_data['Sales']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Regressor
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

mse, r2

# Get feature importances
feature_importances = model.feature_importances_
features = X.columns

# Create a DataFrame for visualization
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})

# Sort the DataFrame by importance
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot the feature importances
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.gca().invert_yaxis()
plt.xlabel('Feature Importance')
plt.title('Feature Importances from Random Forest Regressor')
plt.show()